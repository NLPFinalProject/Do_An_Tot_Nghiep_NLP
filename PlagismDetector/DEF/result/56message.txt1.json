{
  "AllFileRatio": [100.0],
  "ListAllFile": ["message.txt"],
  "File1Name": "message.txt",
  "ListFileName": ["message"],
  "ListFile": [
    {
      "data": [
        "from django .from django .import PreprocessingComponent .from urllib .",
        "from ScrapeSearchEngine .from ScrapeSearchEngine .from ScrapeSearchEngine .from ScrapeSearchEngine .",
        "from ScrapeSearchEngine .import urllib .h = requests .",
        "header = h .content type = header .",
        "if ' text ' in content type .",
        "if ' html ' in content type .",
        "# tinyurl = urllib .request .urlopen ( apiurl + url ) .",
        "# return tinyurl .# url = self .",
        "# + urllib .parse .# res = requests .",
        "# # print ( \" STATUS CODE : \" , res .",
        "# # print ( \" SHORT URL : \" , res .",
        "# return res .list url .list url .",
        "list url .list url .list url .# list url = list ( dict .",
        "# res .append ( obj .# list url .",
        "return list ( dict .name = os .",
        "path .r = requests .f = open ( settings .",
        "f .write ( r .return settings .# crawl text from html website then preprocess and give output : list sentence after preprocessing .",
        "html = urlopen ( req ) .soup = BeautifulSoup ( html , features = \" html .",
        "script .text = soup .lines = ( line .",
        "strip ( ) for line in text .",
        "chunks = ( phrase .strip ( ) for line in lines for phrase in line .",
        "text = ' \\ n ' .temp = p .",
        "list para2txt ( text .res = p .",
        "# vncorenlp file = ' D : \\ DH \\ TotNghiep \\ core \\ preprocessing \\ VnCoreNLP \\ VnCoreNLP - 1.1.1 .",
        "return os .# DOC FILE PATH = ' baocao .",
        "STOPWORD FILE PATH = ' stopword .ALPHABET FILE PATH = ' alphabet .",
        "# Th\u1ed1ng k\u00ea t\u1eeb lo\u1ea1i c\u1ee7a m\u1ed9t t\u1eeb .",
        "Xem t\u1eeb \u0111\u00f3 \u0111\u00f3ng vai tr\u00f2 bao nhi\u00eau t\u1eeb lo\u1ea1i , m\u1ed7i t\u1eeb lo\u1ea1i bao nhi\u00eau l\u1ea7n .",
        "w = w tpl [ 0 ] .",
        "return sorted ( word tag dict .# T\u00ecm v\u1ecb tr\u00ed c\u00e2u ch\u1ee9a m\u1ed9t t\u1eeb n\u00e0o \u0111\u00f3 \u1ee9ng v\u1edbi tag ( cho tr\u01b0\u1edbc ) c\u1ee7a t\u1eeb \u0111\u00f3 trong c\u00e2u .",
        "w = w tpl [ 0 ] .",
        "index .# Input : file .elements = f .",
        "elements [ i ] = elements [ i ] .",
        "f .# key l\u00e0 t\u1eeb A , value l\u00e0 s\u1ed1 l\u01b0\u1ee3ng t\u1eeb A c\u00f3 trong v\u0103n b\u1ea3n ( dict ) .",
        "w temp = w [ 0 ] .",
        "result = dict ( sorted ( dic .",
        "# Output : Gi\u00e1 tr\u1ecb TF c\u1ee7a t\u1eebng t\u1eeb ( dict ) .",
        "for key , val in total words dict .",
        "# Output : Gi\u00e1 tr\u1ecb IDF c\u1ee7a t\u1eebng t\u1eeb ( dict ) .",
        "for key , val in total words dict .",
        "idf [ key ] = math .tfidf = { key : tf [ key ] * idf .",
        "get ( key , 0 ) for key in tf .",
        "if tpl [ 0 ] .val + = tfidf [ tpl [ 0 ] .",
        "return dict ( sorted ( val dict .",
        "if sentence [ i ] [ 0 ] .",
        "value + = tfidf [ sentence [ i ] [ 0 ] .",
        "phrase temp .# stopwords : Danh s\u00e1ch c\u00e1c stop word .",
        "VD : v\u00e0 , l\u00e0 , c\u00e1c , trong , ngo\u00e0i , c\u1ee7a , ... ... .",
        ".key = list ( sen tfidf val .",
        "avg len = math .# list para = p .",
        "docx2txt ( \" xla .# pos tag = p .",
        "# list sentence = p .# pos tag ) # \u0111ay l\u00e0 list c\u00e1c c\u00e2u .",
        "# num word = p .num of word ( list sentence ) # s\u1ed1 t\u1eeb c\u1ee7a c\u00e2u \u0111\u1ea7u ti\u00ean t\u01b0\u01a1ng t\u1ef1 cho a [ 1 ] , ... .",
        "# print ( ViTokenizer .# print ( ViPosTagger .",
        "postagging ( ViTokenizer .# print ( ViUtils .",
        "# print ( ViUtils .# a , b , c , d = p .",
        "preprocess link ( \" xla .f = open ( \" xla .",
        "text = f .a = p .docx2txt ( \" xla ."
      ],
      "stt": [
        [1, 1, [1], [100.0]],
        [2, 2, [2, 3], [100.0, 50.649350649350644]],
        [3, 3, [2, 3, 9], [50.649350649350644, 100.0, 50.54945054945055]],
        [4, 3, [4, 5, 6], [100.0, 56.25, 56.25]],
        [
          5,
          4,
          [4, 5, 6, 22],
          [56.25, 100.0, 89.65517241379311, 54.54545454545454]
        ],
        [6, 3, [4, 5, 6], [56.25, 89.65517241379311, 100.0]],
        [
          7,
          5,
          [7, 9, 12, 13, 16],
          [100.0, 50.0, 51.68539325842697, 52.25225225225225, 50.0]
        ],
        [
          8,
          4,
          [8, 12, 13, 15],
          [100.0, 63.63636363636363, 52.27272727272727, 53.96825396825397]
        ],
        [9, 4, [3, 7, 9, 23], [50.54945054945055, 50.0, 100.0, 50.0]],
        [10, 2, [10, 11], [100.0, 80.55555555555556]],
        [11, 3, [10, 11, 56], [80.55555555555556, 100.0, 50.66666666666667]],
        [
          12,
          7,
          [7, 8, 12, 13, 14, 15, 44],
          [
            51.68539325842697, 63.63636363636363, 100.0, 60.0,
            59.70149253731343, 55.38461538461539, 50.74626865671642
          ]
        ],
        [
          13,
          5,
          [7, 8, 12, 13, 52],
          [52.25225225225225, 52.27272727272727, 60.0, 100.0, 50.0]
        ],
        [14, 3, [12, 14, 50], [59.70149253731343, 100.0, 51.515151515151516]],
        [
          15,
          6,
          [8, 12, 15, 23, 36, 44],
          [
            53.96825396825397, 55.38461538461539, 100.0, 51.61290322580645,
            55.73770491803278, 59.375
          ]
        ],
        [16, 3, [7, 16, 57], [50.0, 100.0, 50.0]],
        [17, 1, [17], [100.0]],
        [18, 1, [18], [100.0]],
        [19, 3, [19, 20, 23], [100.0, 58.46153846153847, 50.0]],
        [
          20,
          4,
          [19, 20, 21, 42],
          [58.46153846153847, 100.0, 52.63157894736842, 61.016949152542374]
        ],
        [21, 2, [20, 21], [52.63157894736842, 100.0]],
        [
          22,
          4,
          [5, 22, 51, 58],
          [54.54545454545454, 100.0, 54.23728813559322, 55.73770491803278]
        ],
        [
          23,
          5,
          [9, 15, 19, 23, 51],
          [50.0, 51.61290322580645, 50.0, 100.0, 53.125]
        ],
        [24, 1, [24], [100.0]],
        [25, 1, [25], [100.0]],
        [26, 1, [26], [100.0]],
        [27, 1, [27], [100.0]],
        [28, 1, [28], [100.0]],
        [
          29,
          5,
          [29, 31, 35, 43, 45],
          [
            100.0, 100.0, 74.28571428571429, 51.724137931034484,
            52.38095238095239
          ]
        ],
        [30, 1, [30], [100.0]],
        [
          31,
          5,
          [29, 31, 35, 43, 45],
          [
            100.0, 100.0, 74.28571428571429, 51.724137931034484,
            52.38095238095239
          ]
        ],
        [32, 2, [32, 33], [100.0, 54.285714285714285]],
        [33, 3, [32, 33, 45], [54.285714285714285, 100.0, 55.172413793103445]],
        [34, 1, [34], [100.0]],
        [
          35,
          4,
          [29, 31, 35, 45],
          [74.28571428571429, 74.28571428571429, 100.0, 60.46511627906976]
        ],
        [
          36,
          4,
          [15, 36, 44, 49],
          [55.73770491803278, 100.0, 79.36507936507937, 50.847457627118644]
        ],
        [37, 2, [37, 39], [100.0, 96.62921348314607]],
        [38, 2, [38, 40], [100.0, 100.0]],
        [39, 2, [37, 39], [96.62921348314607, 100.0]],
        [40, 2, [38, 40], [100.0, 100.0]],
        [41, 2, [41, 43], [100.0, 52.63157894736842]],
        [42, 2, [20, 42], [61.016949152542374, 100.0]],
        [
          43,
          6,
          [29, 31, 41, 43, 45, 46],
          [
            51.724137931034484, 51.724137931034484, 52.63157894736842, 100.0,
            51.515151515151516, 61.72839506172839
          ]
        ],
        [
          44,
          5,
          [12, 15, 36, 44, 49],
          [
            50.74626865671642, 59.375, 79.36507936507937, 100.0,
            51.61290322580645
          ]
        ],
        [
          45,
          7,
          [29, 31, 33, 35, 43, 45, 46],
          [
            52.38095238095239, 52.38095238095239, 55.172413793103445,
            60.46511627906976, 51.515151515151516, 100.0, 76.92307692307693
          ]
        ],
        [46, 3, [43, 45, 46], [61.72839506172839, 76.92307692307693, 100.0]],
        [47, 1, [47], [100.0]],
        [48, 1, [48], [100.0]],
        [49, 3, [36, 44, 49], [50.847457627118644, 51.61290322580645, 100.0]],
        [50, 3, [14, 50, 51], [51.515151515151516, 100.0, 51.515151515151516]],
        [
          51,
          6,
          [22, 23, 50, 51, 57, 58],
          [
            54.23728813559322, 53.125, 51.515151515151516, 100.0, 50.0,
            52.94117647058824
          ]
        ],
        [52, 2, [13, 52], [50.0, 100.0]],
        [53, 1, [53], [100.0]],
        [54, 2, [54, 55], [100.0, 74.72527472527473]],
        [55, 2, [54, 55], [74.72527472527473, 100.0]],
        [56, 2, [11, 56], [50.66666666666667, 100.0]],
        [57, 3, [16, 51, 57], [50.0, 50.0, 100.0]],
        [58, 3, [22, 51, 58], [55.73770491803278, 52.94117647058824, 100.0]]
      ]
    }
  ],
  "file1": [
    "from django .from django .import PreprocessingComponent .from urllib .",
    "from ScrapeSearchEngine .from ScrapeSearchEngine .from ScrapeSearchEngine .from ScrapeSearchEngine .",
    "from ScrapeSearchEngine .import urllib .h = requests .",
    "header = h .content type = header .",
    "if ' text ' in content type .",
    "if ' html ' in content type .",
    "# tinyurl = urllib .request .urlopen ( apiurl + url ) .",
    "# return tinyurl .# url = self .",
    "# + urllib .parse .# res = requests .",
    "# # print ( \" STATUS CODE : \" , res .",
    "# # print ( \" SHORT URL : \" , res .",
    "# return res .list url .list url .",
    "list url .list url .list url .# list url = list ( dict .",
    "# res .append ( obj .# list url .",
    "return list ( dict .name = os .",
    "path .r = requests .f = open ( settings .",
    "f .write ( r .return settings .# crawl text from html website then preprocess and give output : list sentence after preprocessing .",
    "html = urlopen ( req ) .soup = BeautifulSoup ( html , features = \" html .",
    "script .text = soup .lines = ( line .",
    "strip ( ) for line in text .",
    "chunks = ( phrase .strip ( ) for line in lines for phrase in line .",
    "text = ' \\ n ' .temp = p .",
    "list para2txt ( text .res = p .",
    "# vncorenlp file = ' D : \\ DH \\ TotNghiep \\ core \\ preprocessing \\ VnCoreNLP \\ VnCoreNLP - 1.1.1 .",
    "return os .# DOC FILE PATH = ' baocao .",
    "STOPWORD FILE PATH = ' stopword .ALPHABET FILE PATH = ' alphabet .",
    "# Th\u1ed1ng k\u00ea t\u1eeb lo\u1ea1i c\u1ee7a m\u1ed9t t\u1eeb .",
    "Xem t\u1eeb \u0111\u00f3 \u0111\u00f3ng vai tr\u00f2 bao nhi\u00eau t\u1eeb lo\u1ea1i , m\u1ed7i t\u1eeb lo\u1ea1i bao nhi\u00eau l\u1ea7n .",
    "w = w tpl [ 0 ] .",
    "return sorted ( word tag dict .# T\u00ecm v\u1ecb tr\u00ed c\u00e2u ch\u1ee9a m\u1ed9t t\u1eeb n\u00e0o \u0111\u00f3 \u1ee9ng v\u1edbi tag ( cho tr\u01b0\u1edbc ) c\u1ee7a t\u1eeb \u0111\u00f3 trong c\u00e2u .",
    "w = w tpl [ 0 ] .",
    "index .# Input : file .elements = f .",
    "elements [ i ] = elements [ i ] .",
    "f .# key l\u00e0 t\u1eeb A , value l\u00e0 s\u1ed1 l\u01b0\u1ee3ng t\u1eeb A c\u00f3 trong v\u0103n b\u1ea3n ( dict ) .",
    "w temp = w [ 0 ] .",
    "result = dict ( sorted ( dic .",
    "# Output : Gi\u00e1 tr\u1ecb TF c\u1ee7a t\u1eebng t\u1eeb ( dict ) .",
    "for key , val in total words dict .",
    "# Output : Gi\u00e1 tr\u1ecb IDF c\u1ee7a t\u1eebng t\u1eeb ( dict ) .",
    "for key , val in total words dict .",
    "idf [ key ] = math .tfidf = { key : tf [ key ] * idf .",
    "get ( key , 0 ) for key in tf .",
    "if tpl [ 0 ] .val + = tfidf [ tpl [ 0 ] .",
    "return dict ( sorted ( val dict .",
    "if sentence [ i ] [ 0 ] .",
    "value + = tfidf [ sentence [ i ] [ 0 ] .",
    "phrase temp .# stopwords : Danh s\u00e1ch c\u00e1c stop word .",
    "VD : v\u00e0 , l\u00e0 , c\u00e1c , trong , ngo\u00e0i , c\u1ee7a , ... ... .",
    ".key = list ( sen tfidf val .",
    "avg len = math .# list para = p .",
    "docx2txt ( \" xla .# pos tag = p .",
    "# list sentence = p .# pos tag ) # \u0111ay l\u00e0 list c\u00e1c c\u00e2u .",
    "# num word = p .num of word ( list sentence ) # s\u1ed1 t\u1eeb c\u1ee7a c\u00e2u \u0111\u1ea7u ti\u00ean t\u01b0\u01a1ng t\u1ef1 cho a [ 1 ] , ... .",
    "# print ( ViTokenizer .# print ( ViPosTagger .",
    "postagging ( ViTokenizer .# print ( ViUtils .",
    "# print ( ViUtils .# a , b , c , d = p .",
    "preprocess link ( \" xla .f = open ( \" xla .",
    "text = f .a = p .docx2txt ( \" xla ."
  ]
}
